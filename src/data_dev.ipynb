{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importation, Cleaning, and Transformation\n",
    "\n",
    "Data Source: https://eodhistoricaldata.com/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib as jl\n",
    "import datetime as dt\n",
    "import requests\n",
    "\n",
    "from icecream import ic\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from ta import add_all_ta_features\n",
    "from ta.trend import MACD\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.volume import VolumeWeightedAveragePrice\n",
    "from ta.momentum import StochRSIIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API keys from .env file\n",
    "load_dotenv()\n",
    "TRADIER_TOKEN = os.getenv('TRADIER_TOKEN')\n",
    "EOD_TOKEN = os.getenv('EOD_TOKEN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_etf_tickers(): \n",
    "    \n",
    "    # pulls all tickers of ETFs on NYSE or NASDAQ\n",
    "\n",
    "    r = requests.get('https://eodhistoricaldata.com/api/exchange-symbol-list/US', \n",
    "        params={'api_token': EOD_TOKEN, 'fmt': 'json'}\n",
    "        )\n",
    "    data = r.json()\n",
    "    r.close()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df[\n",
    "        (df.Type == 'ETF') &\n",
    "        ((df.Exchange == 'NYSE ARCA') |\n",
    "        (df.Exchange == 'NASDAQ'))\n",
    "        ]\n",
    "\n",
    "    df.index = df.Code\n",
    "    df.drop('Code', axis = 1, inplace=True)\n",
    "    ticker_list = list(df.index)\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get etf tickers\n",
    "# tickers = get_etf_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ticker list to csv\n",
    "# df = pd.DataFrame(tickers)\n",
    "# df.to_csv('data/tickers.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Historical Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_price(tickers, data_type):\n",
    "\n",
    "    # pulls historical daily or intraday OLHC prices and volume\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    for i in range(len(tickers)): \n",
    "\n",
    "        r = requests.get('https://eodhistoricaldata.com/api' + '/' + data_type + '/' + tickers[i] + '.US', \n",
    "            params={'api_token': EOD_TOKEN, 'fmt': 'json'}\n",
    "            )\n",
    "        data = r.json()\n",
    "        r.close()\n",
    "\n",
    "        # ADD PROGRESS BAR\n",
    "        \n",
    "        # remove unecessary loop\n",
    "        for symbol in tickers:\n",
    "            d[symbol] = pd.DataFrame.from_records(data)\n",
    "\n",
    "            indicator_macd = MACD(close = d[symbol]['close'], window_slow=26, window_fast=12, window_sign=9, fillna=True)\n",
    "            d[symbol]['macd'] = indicator_macd.macd()\n",
    "            d[symbol]['macd_diff'] = indicator_macd.macd_diff()\n",
    "            d[symbol]['macd_signal'] = indicator_macd.macd_signal()\n",
    "\n",
    "            indicator_bb = BollingerBands(close = d[symbol]['close'], window=20, window_dev=2, fillna=True)\n",
    "            d[symbol]['bb_mavg'] = indicator_bb.bollinger_mavg()\n",
    "            d[symbol]['bb_hband'] = indicator_bb.bollinger_hband()\n",
    "            d[symbol]['bb_lband'] = indicator_bb.bollinger_lband()\n",
    "            d[symbol]['bb_hband_ind'] = indicator_bb.bollinger_hband_indicator()\n",
    "            d[symbol]['bb_lband_ind'] = indicator_bb.bollinger_lband_indicator()\n",
    "\n",
    "            indicator_vwap = VolumeWeightedAveragePrice(\n",
    "                high = d[symbol]['high'],\n",
    "                low = d[symbol]['low'],\n",
    "                close = d[symbol]['close'],\n",
    "                volume = d[symbol]['volume'],\n",
    "                window=14, fillna=True)\n",
    "            d[symbol]['vwap'] = indicator_vwap.volume_weighted_average_price()\n",
    "\n",
    "            indicator_stochrsi = StochRSIIndicator(close = d[symbol]['close'], window=14, smooth1=3, smooth2=3, fillna=True)\n",
    "            d[symbol]['stoch_rsi'] = indicator_stochrsi.stochrsi()\n",
    "            d[symbol]['stochrsi_d'] = indicator_stochrsi.stochrsi_d()\n",
    "            d[symbol]['stochrsi_k'] = indicator_stochrsi.stochrsi_k()\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder tickers\n",
    "tickers = ['SPXL', 'SPXS']\n",
    "\n",
    "# get intraday prices | dictionary of dataframes\n",
    "intraday_data = get_historical_price(tickers, 'intraday')\n",
    "\n",
    "# get daily prices | dictionary of dataframes\n",
    "daily_data = get_historical_price(tickers, 'eod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat intraday dataframes together and convert to dask df\n",
    "intraday_df = pd.concat(intraday_data.values(), axis=1, keys=intraday_data.keys())\n",
    "intraday_dask_df = dd.from_pandas(intraday_df, npartitions=6)\n",
    "\n",
    "# concat daily dataframes together and convert to dask df\n",
    "daily_df = pd.concat(daily_data.values(), axis=1, keys=daily_data.keys())\n",
    "daily_dask_df = dd.from_pandas(daily_df, npartitions=6)\n",
    "\n",
    "#daily_df.to_csv('data/test_daily_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ETF Fundementals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fundementals(tickers): \n",
    "\n",
    "    # pulls fundementals and wrangles data into multiple dfs\n",
    "\n",
    "    raw_data = {}\n",
    "    single_ticker_clean_data = {}\n",
    "    all_clean_data = {}\n",
    "\n",
    "\n",
    "    columns = ['ISIN', 'Company_Name', 'Company_URL', 'ETF_URL', 'Domicile',\n",
    "        'Index_Name', 'Yield', 'Dividend_Paying_Frequency', 'Inception_Date',\n",
    "        'Max_Annual_Mgmt_Charge', 'Ongoing_Charge', 'Date_Ongoing_Charge',\n",
    "        'NetExpenseRatio', 'AnnualHoldingsTurnover', 'TotalAssets', 'Holdings_Count',\n",
    "        'Average_Mkt_Cap_Mil']\n",
    "\n",
    "    for i in range(len(tickers)): \n",
    "        \n",
    "        r = requests.get('https://eodhistoricaldata.com/api/fundamentals/' + tickers[i] + '.US', \n",
    "            params={'api_token': '63dc0e2f4efc43.34327983', 'fmt': 'json'}\n",
    "            )\n",
    "        data = r.json()\n",
    "        \n",
    "        r.close()\n",
    "\n",
    "        # place raw data for each ticker inside nested dict\n",
    "        raw_data[tickers[i]] = data    \n",
    "\n",
    "        a = pd.Series(raw_data[tickers[i]]['General'])\n",
    "\n",
    "        b = pd.Series([raw_data[tickers[i]]['ETF_Data'][name] for name in columns],\n",
    "            index=[name for name in columns])\n",
    "\n",
    "        # figure out fix\n",
    "        # c = pd.DataFrame([d[tickers[i]]['ETF_Data']['Market_Capitalisation']])#,\n",
    "        # index = [d[tickers[i]]['ETF_Data']['Market_Capitalisation'].keys()])\n",
    "        # c = pd.Series(d[symbol]['ETF_Data']['Market_Capitalisation'],\n",
    "        #  index = ['Market_Capitalisation'])\n",
    "\n",
    "\n",
    "        c = pd.Series(raw_data[tickers[i]]['ETF_Data']['MorningStar'])\n",
    "\n",
    "        # figure out fix\n",
    "        # d = pd.DataFrame(d[tickers[i]]['ETF_Data']['Performance'].items(),\n",
    "        #     index = d[tickers[i]]['ETF_Data']['Performance'].keys()).drop(0, axis=1)\n",
    "        # d = pd.DataFrame(d[symbol]['ETF_Data']['Performance'].items(),\n",
    "        #  index = d[symbol]['ETF_Data']['Performance'].keys()).drop(0, axis=1)\n",
    "        \n",
    "        # e = pd.Series(d[symbol]['Technicals'])\n",
    "        # e = pd.Series(d[tickers[i]]['Technicals'].items(), \n",
    "        #     index = d[tickers[i]]['Technicals'].keys()).drop(0, axis=1)\n",
    "\n",
    "        single_ticker_clean_data['general'] = pd.DataFrame(pd.concat([a, b, c]), columns = ['data'])\n",
    "        single_ticker_clean_data['asset_allocation'] = pd.DataFrame(raw_data[tickers[i]]['ETF_Data']['Asset_Allocation'])\n",
    "        region_weights_df = pd.DataFrame(raw_data[tickers[i]]['ETF_Data']['World_Regions'])\n",
    "        sector_weights_df = pd.DataFrame(raw_data[tickers[i]]['ETF_Data']['Sector_Weights'])\n",
    "        single_ticker_clean_data['fixed_income'] = pd.DataFrame(raw_data[tickers[i]]['ETF_Data']['Fixed_Income'])\n",
    "        single_ticker_clean_data['top_10_holdings'] = pd.DataFrame(raw_data[tickers[i]]['ETF_Data']['Top_10_Holdings'].values(), index = raw_data[tickers[i]]['ETF_Data']['Top_10_Holdings'].keys())\n",
    "        single_ticker_clean_data['holdings'] = pd.DataFrame(raw_data[tickers[i]]['ETF_Data']['Holdings'].values(), index = raw_data[tickers[i]]['ETF_Data']['Holdings'].keys())\n",
    "        single_ticker_clean_data['valuations_growth'] = pd.DataFrame(raw_data[tickers[i]]['ETF_Data']['Valuations_Growth']).T\n",
    "\n",
    "        placeholder = {}\n",
    "        placeholder['region_weights'] = region_weights_df\n",
    "        placeholder['sector_weights'] = sector_weights_df\n",
    "        weights_df = pd.concat(placeholder.values(), axis=1, keys=placeholder.keys())\n",
    "        single_ticker_clean_data['weights'] = weights_df.copy()\n",
    "\n",
    "        all_clean_data[tickers[i]] = single_ticker_clean_data\n",
    "\n",
    "\n",
    "    return all_clean_data, single_ticker_clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # placeholder tickers\n",
    "tickers = ['SPY', 'QQQ']\n",
    "\n",
    "# # get fundemental data\n",
    "fundemental_data, single_ticker = get_fundementals(tickers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Dev\n",
    "- then develop flow for analysis on whiteboard, use paper as resource"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Stock Fundementals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tickers): \n",
    "\n",
    "    raw_data = {}\n",
    "    single_ticker_clean_data = {}\n",
    "    all_clean_data = {}\n",
    "\n",
    "    columns = ['General', 'Highlights']\n",
    "\n",
    "    for i in range(len(tickers)): \n",
    "\n",
    "        r = requests.get('https://eodhistoricaldata.com/api/fundamentals/' + tickers[i] + '.US', \n",
    "            params={'api_token': '63dc0e2f4efc43.34327983', 'fmt': 'json'}\n",
    "            )\n",
    "        data = r.json()\n",
    "        \n",
    "        r.close()\n",
    "\n",
    "        raw_data[tickers[i]] = data\n",
    "        \n",
    "        Officers = raw_data[tickers[i]]['General'].pop('Officers', None)\n",
    "        Listings = raw_data[tickers[i]]['General'].pop('Listings', None)\n",
    "        AddressData = raw_data[tickers[i]]['General'].pop('AddressData', None)\n",
    "        general = pd.Series(raw_data[tickers[i]]['General'])\n",
    "        highlights = pd.Series(raw_data[tickers[i]]['Highlights'])\n",
    "        valuation = pd.Series(raw_data[tickers[i]]['Valuation'])\n",
    "        # pd.Series(raw_data[tickers[i]]['SharesStats'])\n",
    "        # pd.Series(raw_data[tickers[i]]['Technicals'])\n",
    "        # NumberDividendsByYear = raw_data[tickers[i]]['SplitsDividends'].pop('NumberDividendsByYear', None)\n",
    "        # pd.Series(raw_data[tickers[i]]['SplitsDividends'])\n",
    "        # pd.Series(raw_data[tickers[i]]['AnalystRatings'])\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Holders']['Institutions']).T.set_index(['name'])\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Holders']['Funds']).T.set_index(['name'])\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['InsiderTransactions']).T.set_index(['date'])\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['outstandingShares']['annual']).T.set_index('dateFormatted')\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['outstandingShares']['quarterly']).T.set_index('dateFormatted')\n",
    "        \n",
    "        # # join on date\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Earnings']['History']).T\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Earnings']['Trend']).T\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Earnings']['Annual']).T\n",
    "        \n",
    "        # # join on date\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Financials']['Balance_Sheet']['quarterly']).T\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Financials']['Cash_Flow']['quarterly']).T\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Financials']['Income_Statement']['quarterly']).T\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Financials']['Balance_Sheet']['yearly']).T\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Financials']['Cash_Flow']['yearly']).T\n",
    "        # pd.DataFrame(raw_data[tickers[i]]['Financials']['Income_Statement']['yearly']).T\n",
    "\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tickers \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAAPL\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m fundemental_data \u001b[39m=\u001b[39m test(tickers)\n",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m      7\u001b[0m columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mGeneral\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mHighlights\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(tickers)): \n\u001b[0;32m---> 11\u001b[0m     r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mhttps://eodhistoricaldata.com/api/fundamentals/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m tickers[i] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.US\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     12\u001b[0m         params\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mapi_token\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m63dc0e2f4efc43.34327983\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfmt\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m     data \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n\u001b[1;32m     16\u001b[0m     r\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "tickers = ['AAPL']\n",
    "fundemental_data = test(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundemental_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# officers = fundemental_data['General'].pop('Officers', None)\n",
    "# listings = fundemental_data['General'].pop('Listings', None)\n",
    "# address = fundemental_data['General'].pop('AddressData', None)\n",
    "# pd.Series(fundemental_data['General'])\n",
    "# pd.Series(fundemental_data['Highlights'])\n",
    "# pd.Series(fundemental_data['Valuation'])\n",
    "# pd.Series(fundemental_data['SharesStats'])\n",
    "# pd.Series(fundemental_data['Technicals'])\n",
    "# NumberDividendsByYear = fundemental_data['SplitsDividends'].pop('NumberDividendsByYear', None)\n",
    "# pd.Series(fundemental_data['SplitsDividends'])\n",
    "# pd.Series(fundemental_data['AnalystRatings'])\n",
    "# pd.DataFrame(fundemental_data['Holders']['Institutions']).T.set_index(['name'])\n",
    "# pd.DataFrame(fundemental_data['Holders']['Funds']).T.set_index(['name'])\n",
    "# pd.DataFrame(fundemental_data['InsiderTransactions']).T.set_index(['date'])\n",
    "# pd.DataFrame(fundemental_data['outstandingShares']['annual']).T.set_index('dateFormatted')\n",
    "# pd.DataFrame(fundemental_data['outstandingShares']['quarterly']).T.set_index('dateFormatted')\n",
    "# # join on date\n",
    "# pd.DataFrame(fundemental_data['Earnings']['History']).T\n",
    "# pd.DataFrame(fundemental_data['Earnings']['Trend']).T\n",
    "# pd.DataFrame(fundemental_data['Earnings']['Annual']).T\n",
    "# # join on date\n",
    "# pd.DataFrame(fundemental_data['Financials']['Balance_Sheet']['quarterly']).T\n",
    "# pd.DataFrame(fundemental_data['Financials']['Cash_Flow']['quarterly']).T\n",
    "# pd.DataFrame(fundemental_data['Financials']['Income_Statement']['quarterly']).T\n",
    "# pd.DataFrame(fundemental_data['Financials']['Balance_Sheet']['yearly']).T\n",
    "# pd.DataFrame(fundemental_data['Financials']['Cash_Flow']['yearly']).T\n",
    "# pd.DataFrame(fundemental_data['Financials']['Income_Statement']['yearly']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honors-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cec9fab241fb47ace68fb2f1a373c81bce58fef94d497d1b6d3a75b16829e6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
